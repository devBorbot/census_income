{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "983f5ce0-b235-4adf-bd2c-550948c4a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed119cef-a5f1-44fc-8916-a1b3f20a7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde4d2c9-233c-490b-b3d5-2c15da028eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "census_income_learn.csv census_income_test.csv\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a219baa2-81c2-409f-8d85-ac16aa8ea730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "census_income_additional_info.pdf data_cols.csv\n",
      "census_income_metadata.txt        data_cols.numbers\n"
     ]
    }
   ],
   "source": [
    "!ls sup_info/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1caed63-0171-4c02-96a8-1f4f7d0080d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_info = [\n",
    "    \"|   91 distinct values for attribute #0 (age) continuous\",\n",
    "    \"|    9 distinct values for attribute #1 (class of worker) nominal\",\n",
    "    \"|   52 distinct values for attribute #2 (detailed industry recode) nominal\",\n",
    "    \"|   47 distinct values for attribute #3 (detailed occupation recode) nominal\",\n",
    "    \"|   17 distinct values for attribute #4 (education) nominal\",\n",
    "    \"| 1240 distinct values for attribute #5 (wage per hour) continuous\",\n",
    "    \"|    3 distinct values for attribute #6 (enroll in edu inst last wk) nominal\",\n",
    "    \"|    7 distinct values for attribute #7 (marital stat) nominal\",\n",
    "    \"|   24 distinct values for attribute #8 (major industry code) nominal\",\n",
    "    \"|   15 distinct values for attribute #9 (major occupation code) nominal\",\n",
    "    \"|    5 distinct values for attribute #10 (race) nominal\",\n",
    "    \"|   10 distinct values for attribute #11 (hispanic origin) nominal\",\n",
    "    \"|    2 distinct values for attribute #12 (sex) nominal\",\n",
    "    \"|    3 distinct values for attribute #13 (member of a labor union) nominal\",\n",
    "    \"|    6 distinct values for attribute #14 (reason for unemployment) nominal\",\n",
    "    \"|    8 distinct values for attribute #15 (full or part time employment stat) nominal\",\n",
    "    \"|  132 distinct values for attribute #16 (capital gains) continuous\",\n",
    "    \"|  113 distinct values for attribute #17 (capital losses) continuous\",\n",
    "    \"| 1478 distinct values for attribute #18 (dividends from stocks) continuous\",\n",
    "    \"|    6 distinct values for attribute #19 (tax filer stat) nominal\",\n",
    "    \"|    6 distinct values for attribute #20 (region of previous residence) nominal\",\n",
    "    \"|   51 distinct values for attribute #21 (state of previous residence) nominal\",\n",
    "    \"|   38 distinct values for attribute #22 (detailed household and family stat) nominal\",\n",
    "    \"|    8 distinct values for attribute #23 (detailed household summary in household) nominal\",\n",
    "    \"|   10 distinct values for attribute #24 (migration code-change in msa) nominal\",\n",
    "    \"|    9 distinct values for attribute #25 (migration code-change in reg) nominal\",\n",
    "    \"|   10 distinct values for attribute #26 (migration code-move within reg) nominal\",\n",
    "    \"|    3 distinct values for attribute #27 (live in this house 1 year ago) nominal\",\n",
    "    \"|    4 distinct values for attribute #28 (migration prev res in sunbelt) nominal\",\n",
    "    \"|    7 distinct values for attribute #29 (num persons worked for employer) continuous\",\n",
    "    \"|    5 distinct values for attribute #30 (family members under 18) nominal\",\n",
    "    \"|   43 distinct values for attribute #31 (country of birth father) nominal\",\n",
    "    \"|   43 distinct values for attribute #32 (country of birth mother) nominal\",\n",
    "    \"|   43 distinct values for attribute #33 (country of birth self) nominal\",\n",
    "    \"|    5 distinct values for attribute #34 (citizenship) nominal\",\n",
    "    \"|    3 distinct values for attribute #35 (own business or self employed) nominal\",\n",
    "    \"|    3 distinct values for attribute #36 (fill inc questionnaire for veteran's admin) nominal\",\n",
    "    \"|    3 distinct values for attribute #37 (veterans benefits) nominal\",\n",
    "    \"|   53 distinct values for attribute #38 (weeks worked in year) continuous\",\n",
    "    \"|    2 distinct values for attribute #39 (year) nominal\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807ed1ae-bf65-4e50-8dfc-2be9e0a97b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data_info = pd.Series(data_info)\\\n",
    "    .str.replace(\"|\", \"\")\\\n",
    "    .str.replace(\"distinct values for attribute #\", \",\")\\\n",
    "    .str.replace(\"(\", \",\")\\\n",
    "    .str.replace(\")\", \",\")\\\n",
    "    .str.replace(\"'\",\"\")\\\n",
    "    .str.strip()\n",
    "df_data_info = s_data_info.str.split(\",\", expand=True).drop(1,axis=1)\n",
    "df_data_info.columns = [\"nunique\", \"column_name\", \"column_type\"]\n",
    "df_data_info[\"nunique\"] = df_data_info[\"nunique\"].astype(int)\n",
    "df_data_info.loc[40] = [2, \"target\", \"nominal\"]\n",
    "df_data_info = df_data_info.map(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b307ddc7-3307-4984-b00f-85688af77cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199523, 41)\n",
      "46627\n",
      "renaming columns\n"
     ]
    }
   ],
   "source": [
    "df0 = pd.read_csv(\n",
    "    filepath_or_buffer=\"data/census_income_learn.csv\",\n",
    "    header=None).drop(24,axis=1)\n",
    "print(df0.shape)\n",
    "print(df0.duplicated().sum()) # different total than metadata file (46627 vs.46716)\n",
    "if (df0.nunique().reset_index(drop=True) == df_data_info[\"nunique\"]).all():\n",
    "    print(\"renaming columns\")\n",
    "    df0.columns = df_data_info[\"column_name\"].tolist()\n",
    "df0 = df0.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df0 = df0.replace(\"?\", np.nan)\n",
    "df0[\"target\"] = df0[\"target\"].str.replace(\".\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69ed0b4c-0af9-44e7-8551-f8c18b71a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_data_info.iterrows():\n",
    "    if row[\"column_type\"] == \"continuous\":\n",
    "        df0[row[\"column_name\"]] = df0[row[\"column_name\"]].astype(float)\n",
    "    else:\n",
    "        df0[row[\"column_name\"]] = df0[row[\"column_name\"]].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7deb5da0-a88c-4940-80a1-75d16ab2a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # matching column sanity check\n",
    "# (df_data_info[df_data_info[\"column_type\"]==\"nominal\"][\"column_name\"].values == df0.select_dtypes(object).columns).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06dd5c0b-2e55-4ff3-bea5-83616890f26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class of worker\n",
      "100245\n",
      "detailed industry recode\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m df_data_info[df_data_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnominal\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(column)\n\u001b[0;32m----> 3\u001b[0m     df0_NIU_mask \u001b[38;5;241m=\u001b[39m \u001b[43mdf0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot in universe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df0_NIU_mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m      5\u001b[0m         df0_NIU_uval \u001b[38;5;241m=\u001b[39m df0[column][df0_NIU_mask]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/GitHub/census_income/venv/lib/python3.11/site-packages/pandas/core/generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6297\u001b[0m ):\n\u001b[1;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/census_income/venv/lib/python3.11/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/Documents/GitHub/census_income/venv/lib/python3.11/site-packages/pandas/core/strings/accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m~/Documents/GitHub/census_income/venv/lib/python3.11/site-packages/pandas/core/strings/accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "for column in df_data_info[df_data_info[\"column_type\"] == \"nominal\"][\"column_name\"]:\n",
    "    print(column)\n",
    "    df0_NIU_mask = df0[column].str.contains(\"Not in universe\")\n",
    "    if df0_NIU_mask.any():\n",
    "        df0_NIU_uval = df0[column][df0_NIU_mask].unique().item()\n",
    "        NIU_count = df0[df0[column] == df0_NIU_uval].shape[0]\n",
    "        print(NIU_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa057834-05ea-4a90-a5fd-5ed6985f8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_info[\"nan_count\"] = df0.isna().sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac05ab40-5f05-42aa-bd64-eca9c40cee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152101, 41)\n",
      "11915\n"
     ]
    }
   ],
   "source": [
    "# if edu is Children then target < 50k\n",
    "df0[df0[\"education\"]==\"Children\"][\"target\"].value_counts()\n",
    "df1 = df0[df0[\"education\"]!=\"Children\"].reset_index(drop=True)\n",
    "print(df1.shape)\n",
    "print(df1.duplicated().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
