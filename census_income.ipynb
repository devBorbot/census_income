{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed119cef-a5f1-44fc-8916-a1b3f20a7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# from IPython.display import display, HTML\n",
    "# display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4d2c9-233c-490b-b3d5-2c15da028eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a219baa2-81c2-409f-8d85-ac16aa8ea730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls sup_info/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5190e7-b190-4187-a3d9-894090312d3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c72e6-098a-45c6-9725-5fba415467ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created append_anomaly_counts function to get anomaly counts with different datasets & slices\n",
    "def append_anomaly_counts(df_info=None, dataframe=None, col_suffix=\"\"):\n",
    "    res = []\n",
    "    df_info[\"nunique\"] = dataframe.nunique().values\n",
    "    df_info[\"uknown_count\"] = dataframe.eq(\"?\").sum().values\n",
    "    for idx, row in df_info.iterrows():\n",
    "        column = row[\"column_name\"]\n",
    "        if row[\"column_type\"] == \"continuous\":\n",
    "            dataframe[column] = dataframe[column].astype(float)\n",
    "            res.append({\"column_name\":column, \"NIU_count\":0})\n",
    "        else:\n",
    "            dataframe[column] = dataframe[column].astype(str)\n",
    "            dataframe_NIU_mask = dataframe[column].str.contains(\"Not in universe\")\n",
    "            if dataframe_NIU_mask.any():\n",
    "                dataframe_NIU_uval = dataframe[column][dataframe_NIU_mask].unique().item()\n",
    "                NIU_count = dataframe[dataframe[column] == dataframe_NIU_uval].shape[0]\n",
    "                res.append({\"column_name\":column, \"NIU_count\":NIU_count})\n",
    "            else:\n",
    "                res.append({\"column_name\":column, \"NIU_count\":0})\n",
    "    # matching nominal column sanity check\n",
    "    if (df_info[df_info[\"column_type\"]==\"nominal\"][\"column_name\"].values == dataframe.select_dtypes(object).columns).all():\n",
    "        df_info = pd.concat([df_info, pd.DataFrame(res)[\"NIU_count\"]], axis=1)\n",
    "        df_info = df_info.assign(row_count=dataframe.shape[0])\n",
    "    return df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936df00c-3805-4ffd-8d67-6d61eaf63c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_target_value(dataframe=None):\n",
    "    dataframe.loc[dataframe[\"target\"] == \"- 50000\", \"target\"] = \"0\"\n",
    "    dataframe.loc[dataframe[\"target\"] == \"50000+\", \"target\"] = \"1\"\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e02d7b-3c74-4f23-8153-74c95d790ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_cat_column(dataframe=None, column=\"\", remap={}):\n",
    "    return dataframe.replace({column:remap})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0007145-0661-4c96-9333-0232aaa3e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_target_eda(dataframe=None, column=\"\", order=None, plot=True):\n",
    "    ct = pd.crosstab(dataframe[\"target\"], dataframe[column], normalize=\"index\")\n",
    "    if plot:\n",
    "        display(ct)\n",
    "        g = sns.catplot(\n",
    "            x=column,\n",
    "            kind=\"count\",\n",
    "            col=\"target\",\n",
    "            order=order,\n",
    "            data=dataframe,\n",
    "            sharey=False,\n",
    "        )\n",
    "        g.set_xticklabels(rotation=60)\n",
    "    return ct.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93021e9-29be-49df-85a1-35c1a2831f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_nominal(dataframe=None, columns=None, threshold=0.01):\n",
    "    res = []\n",
    "    for column in columns:\n",
    "        remap = {}\n",
    "        ct = categorical_target_eda(dataframe=dataframe, column=column, plot=False)\n",
    "        s = ct[\"50000+\"] - ct[\"- 50000\"]\n",
    "        for category, value in zip(s.index, s):\n",
    "            if value > threshold:\n",
    "                remap[category] = \"gt\"\n",
    "            elif value < -threshold:\n",
    "                remap[category] = \"lt\"\n",
    "            else:\n",
    "                remap[category] = \"eq\"\n",
    "        res.append({column:remap})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8952de5e-55d3-4def-889b-ffc91b431803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_cat_columns(train_data=None, test_data=None, remaps=None, verbose=0):\n",
    "    # select float columns for concatenation\n",
    "    df_train_floats = train_data.select_dtypes(include=float)\n",
    "    df_test_floats = test_data.select_dtypes(include=float)\n",
    "    # initalize dataframes for concatenation\n",
    "    df_train_remap = pd.DataFrame()\n",
    "    df_test_remap = pd.DataFrame()\n",
    "    # loop through list of dictionaries and remap values in categorical columns\n",
    "    for remap in remaps:\n",
    "        # get column from dictionary\n",
    "        column = list(remap.keys())[0]\n",
    "        # remap train\n",
    "        df_train_temp = remap_cat_column(dataframe=train_data, column=column, remap=remap[column])\n",
    "        df_train_remap = pd.concat([df_train_remap, df_train_temp[column]], axis=1)\n",
    "        # remap test\n",
    "        df_test_temp = remap_cat_column(dataframe=test_data, column=column, remap=remap[column])\n",
    "        df_test_remap = pd.concat([df_test_remap, df_test_temp[column]], axis=1)\n",
    "    \n",
    "    df_train_remap = pd.concat([df_train_floats, df_train_remap, train_data[\"target\"]], axis=1)\n",
    "    df_test_remap = pd.concat([df_test_floats, df_test_remap, test_data[\"target\"]], axis=1)\n",
    "\n",
    "    if verbose > 0:\n",
    "        display(df_train_remap.describe(include=\"float\"))\n",
    "        display(df_train_remap.describe(include=\"object\"))\n",
    "    \n",
    "    return df_train_remap, df_test_remap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f7fe84-808c-4822-9795-c7c1d51779d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc6483-094e-46d3-828f-ca3797af54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train0 = pd.read_csv(\n",
    "    filepath_or_buffer=\"data/census_income_learn.csv\",\n",
    "    header=None).drop(24,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957917d-4f5f-4a9e-bfa0-675c9594fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test0 = pd.read_csv(\n",
    "    filepath_or_buffer=\"data/census_income_test.csv\",\n",
    "    header=None).drop(24,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1caed63-0171-4c02-96a8-1f4f7d0080d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = [\n",
    "    \"|   91 distinct values for attribute #0 (age) continuous\",\n",
    "    \"|    9 distinct values for attribute #1 (class of worker) nominal\",\n",
    "    \"|   52 distinct values for attribute #2 (detailed industry recode) nominal\",\n",
    "    \"|   47 distinct values for attribute #3 (detailed occupation recode) nominal\",\n",
    "    \"|   17 distinct values for attribute #4 (education) nominal\",\n",
    "    \"| 1240 distinct values for attribute #5 (wage per hour) continuous\",\n",
    "    \"|    3 distinct values for attribute #6 (enroll in edu inst last wk) nominal\",\n",
    "    \"|    7 distinct values for attribute #7 (marital stat) nominal\",\n",
    "    \"|   24 distinct values for attribute #8 (major industry code) nominal\",\n",
    "    \"|   15 distinct values for attribute #9 (major occupation code) nominal\",\n",
    "    \"|    5 distinct values for attribute #10 (race) nominal\",\n",
    "    \"|   10 distinct values for attribute #11 (hispanic origin) nominal\",\n",
    "    \"|    2 distinct values for attribute #12 (sex) nominal\",\n",
    "    \"|    3 distinct values for attribute #13 (member of a labor union) nominal\",\n",
    "    \"|    6 distinct values for attribute #14 (reason for unemployment) nominal\",\n",
    "    \"|    8 distinct values for attribute #15 (full or part time employment stat) nominal\",\n",
    "    \"|  132 distinct values for attribute #16 (capital gains) continuous\",\n",
    "    \"|  113 distinct values for attribute #17 (capital losses) continuous\",\n",
    "    \"| 1478 distinct values for attribute #18 (dividends from stocks) continuous\",\n",
    "    \"|    6 distinct values for attribute #19 (tax filer stat) nominal\",\n",
    "    \"|    6 distinct values for attribute #20 (region of previous residence) nominal\",\n",
    "    \"|   51 distinct values for attribute #21 (state of previous residence) nominal\",\n",
    "    \"|   38 distinct values for attribute #22 (detailed household and family stat) nominal\",\n",
    "    \"|    8 distinct values for attribute #23 (detailed household summary in household) nominal\",\n",
    "    \"|   10 distinct values for attribute #24 (migration code-change in msa) nominal\",\n",
    "    \"|    9 distinct values for attribute #25 (migration code-change in reg) nominal\",\n",
    "    \"|   10 distinct values for attribute #26 (migration code-move within reg) nominal\",\n",
    "    \"|    3 distinct values for attribute #27 (live in this house 1 year ago) nominal\",\n",
    "    \"|    4 distinct values for attribute #28 (migration prev res in sunbelt) nominal\",\n",
    "    \"|    7 distinct values for attribute #29 (num persons worked for employer) continuous\",\n",
    "    \"|    5 distinct values for attribute #30 (family members under 18) nominal\",\n",
    "    \"|   43 distinct values for attribute #31 (country of birth father) nominal\",\n",
    "    \"|   43 distinct values for attribute #32 (country of birth mother) nominal\",\n",
    "    \"|   43 distinct values for attribute #33 (country of birth self) nominal\",\n",
    "    \"|    5 distinct values for attribute #34 (citizenship) nominal\",\n",
    "    \"|    3 distinct values for attribute #35 (own business or self employed) nominal\",\n",
    "    \"|    3 distinct values for attribute #36 (fill inc questionnaire for veteran's admin) nominal\",\n",
    "    \"|    3 distinct values for attribute #37 (veterans benefits) nominal\",\n",
    "    \"|   53 distinct values for attribute #38 (weeks worked in year) continuous\",\n",
    "    \"|    2 distinct values for attribute #39 (year) nominal\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1fd32-354f-4540-b7a4-603027c609f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ed1ae-bf65-4e50-8dfc-2be9e0a97b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data_info = pd.Series(data_info)\\\n",
    "    .str.replace(\"|\", \"\")\\\n",
    "    .str.replace(\"distinct values for attribute #\", \",\")\\\n",
    "    .str.replace(\"(\", \",\")\\\n",
    "    .str.replace(\")\", \",\")\\\n",
    "    .str.replace(\"'\",\"\")\\\n",
    "    .str.strip()\n",
    "df_data_info = s_data_info.str.split(\",\", expand=True).drop(1,axis=1)\n",
    "df_data_info.columns = [\"nunique\", \"column_name\", \"column_type\"]\n",
    "df_data_info[\"nunique\"] = df_data_info[\"nunique\"].astype(int)\n",
    "df_data_info.loc[40] = [2, \"target\", \"nominal\"]\n",
    "df_data_info = df_data_info.map(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f760877-c430-4b9f-a966-4b8169daa12f",
   "metadata": {},
   "source": [
    "#### train data clean\n",
    "- df_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca304a-0bf6-4ffe-95b5-951640c99e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"inital shape: {df_train0.shape}\")\n",
    "print(f\"number of dups: {df_train0.duplicated().sum()}\") # different total than metadata file (46627 vs.46716)\n",
    "if (df_train0.nunique().reset_index(drop=True) == df_data_info[\"nunique\"]).all():\n",
    "    print(\"renaming columns\\n\")\n",
    "    df_train0.columns = df_data_info[\"column_name\"].tolist()\n",
    "df_train0 = df_train0.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_train0[\"target\"] = df_train0[\"target\"].str.replace(\".\", \"\")\n",
    "\n",
    "# drop duplicate rows\n",
    "df_train1 = df_train0.drop_duplicates(ignore_index=True)\n",
    "print(f\"shape after drop dups: {df_train1.shape}\")\n",
    "\n",
    "# if edu is Children then target < 50k\n",
    "print(\"\\nfilter Children - target counts\")\n",
    "print(df_train1[df_train1[\"education\"]==\"Children\"][\"target\"].value_counts())\n",
    "\n",
    "df_train1 = df_train1[df_train1[\"education\"]!=\"Children\"].reset_index(drop=True)\n",
    "print(f\"\\nshape after drop Children: {df_train1.shape}\")\n",
    "# print(df_train1.duplicated().sum())\n",
    "\n",
    "df_info_train = append_anomaly_counts(df_info=df_data_info, dataframe=df_train1)\n",
    "\n",
    "print(\"\\ntarget distribution\")\n",
    "print(df_train1[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54330587-30c4-4523-ad57-85f226d79159",
   "metadata": {},
   "source": [
    "#### Test data clean\n",
    "- df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6568e-a8c1-492a-b6a0-60d7821061cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"inital shape: {df_test0.shape}\")\n",
    "print(f\"number of dups: {df_test0.duplicated().sum()}\")\n",
    "print(\"renaming columns\\n\")\n",
    "df_test0.columns = df_data_info[\"column_name\"].tolist()\n",
    "df_test0 = df_test0.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_test0[\"target\"] = df_test0[\"target\"].str.replace(\".\", \"\")\n",
    "\n",
    "# drop duplicate rows\n",
    "df_test1 = df_test0.drop_duplicates(ignore_index=True)\n",
    "print(f\"shape after drop dups: {df_test1.shape}\")\n",
    "\n",
    "# if edu is Children then target < 50k\n",
    "print(\"\\nfilter Children - target counts\")\n",
    "print(df_test1[df_test1[\"education\"]==\"Children\"][\"target\"].value_counts())\n",
    "\n",
    "df_test1 = df_test1[df_test1[\"education\"]!=\"Children\"].reset_index(drop=True)\n",
    "print(f\"\\nshape after drop Children: {df_test1.shape}\")\n",
    "# print(df_test1.duplicated().sum())\n",
    "\n",
    "df_info_test = append_anomaly_counts(df_info=df_data_info, dataframe=df_test1)\n",
    "\n",
    "print(\"\\ntarget distribution\")\n",
    "print(df_test1[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f297262b-a471-4574-8445-c380c516e01d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b24420b-4e66-4909-9904-532f4b5a36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter nominal columns and exclude target\n",
    "df_nominal = df_info_train[(df_info_train[\"column_type\"] == \"nominal\") & (df_info_train[\"column_name\"] != \"target\")]\n",
    "\n",
    "# filtered column lists - nominal columns (nc)\n",
    "nc_all = df_nominal[\"column_name\"].values\n",
    "nc_noUnknown = df_nominal[df_nominal[\"uknown_count\"] == 0][\"column_name\"].values\n",
    "nc_noNIU = df_nominal[df_nominal[\"NIU_count\"] == 0][\"column_name\"].values\n",
    "nc_noUnknownORnoNIU = df_nominal[(df_nominal[\"uknown_count\"] == 0) & (df_nominal[\"NIU_count\"] == 0)][\"column_name\"].values\n",
    "\n",
    "res_nc_all = engineer_nominal(dataframe=df_train1, columns=nc_all, threshold=0.01)\n",
    "print(f\"nc_all--dataframe shape: {nc_all.shape[0]} | result column size: {len(res_nc_all)}\")\n",
    "res_nc_noUnknown = engineer_nominal(dataframe=df_train1, columns=nc_noUnknown, threshold=0.01)\n",
    "print(f\"nc_noUnknown--dataframe shape: {nc_noUnknown.shape[0]} | result column size: {len(res_nc_noUnknown)}\")\n",
    "res_nc_noNIU = engineer_nominal(dataframe=df_train1, columns=nc_noNIU, threshold=0.01)\n",
    "print(f\"nc_noNIU--dataframe shape: {nc_noNIU.shape[0]} | result column size: {len(res_nc_noNIU)}\")\n",
    "res_nc_noUnknownORnoNIU = engineer_nominal(dataframe=df_train1, columns=nc_noUnknownORnoNIU, threshold=0.01)\n",
    "print(f\"nc_noUnknownORnoNIU--dataframe shape: {nc_noUnknownORnoNIU.shape[0]} | result column size: {len(res_nc_noUnknownORnoNIU)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa58a2c-e676-4156-b7f1-b3b6b60eb068",
   "metadata": {},
   "source": [
    "#### remap categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df30601-1f46-43ba-a8b4-a987d7300d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_remap, df_test_remap = engineer_cat_columns(\n",
    "    train_data=df_train1,\n",
    "    test_data=df_test1,\n",
    "    remaps=res_nc_all,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27675bb1-4a70-4d59-a244-4610ba0f0ea5",
   "metadata": {},
   "source": [
    "## Model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559f027-3644-47ef-ac27-1ce4f8c67510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = change_target_value(dataframe=df_train_remap)\n",
    "df_test2 = change_target_value(dataframe=df_test_remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eb62c3-8806-44dd-90e8-ed13b6ea4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9be2b-938f-4419-b0df-5875b4a2de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8485ff-4a16-4882-9d9b-11b732f06f46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # BALANCE DATA - NOT USED YET...\n",
    "# df_class0 = df_train2[df_train2[\"target\"] == \"0\"]\n",
    "# df_class1 = df_train2[df_train2[\"target\"] == \"1\"]\n",
    "\n",
    "# df_class0_sample = df_class0.sample(n=df_class1.shape[0], random_state=42, axis=0)\n",
    "# df_train_balance = pd.concat([df_class0_sample, df_class1], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e82e81-639b-41ca-bd9d-9fd0bf1ea70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0 = df_train2.drop(\"target\", axis=1)\n",
    "y_train0 = df_train2[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed855bf0-84b0-4b1a-b800-d2c051342339",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test0 = df_test2.drop(\"target\", axis=1)\n",
    "y_test0 = df_test2[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08647b-4894-4a86-9ea8-ddb596f56a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_cols = X_train0.select_dtypes(object).nunique() == X_test0.select_dtypes(object).nunique()\n",
    "cat_features = matching_cols[matching_cols==True].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc1a9e8-605a-4e1e-84c5-1e8b85fbea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\n",
    "    \"age\",\n",
    "    \"dividends from stocks\",\n",
    "    \"num persons worked for employer\", ###\n",
    "    \"weeks worked in year\", ###\n",
    "]\n",
    "features = num_features + cat_features\n",
    "X_train1 = pd.get_dummies(X_train0.loc[:, features])\n",
    "X_test1 = pd.get_dummies(X_test0.loc[:, features])\n",
    "print(X_train1.shape)\n",
    "print(X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e9862-c352-4f38-a8e4-e131864af02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif as MIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766493cd-abb8-4e3d-af34-299946f6487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_score = MIC(X_train1, y_train0, random_state=42)\n",
    "col_MIC_mask = mi_score > np.percentile(a=mi_score, q=75)\n",
    "selected_features = X_train1.columns[col_MIC_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a8fc9-02a7-4606-9ded-943b03fad215",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train1.loc[:, selected_features]\n",
    "X_test1 = X_test1.loc[:, selected_features]\n",
    "print(X_train1.shape)\n",
    "print(X_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1f8b4-149b-42e8-b15f-389b15a0196c",
   "metadata": {},
   "source": [
    "### logistic regression - baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7555b317-7131-4b5b-b38b-6399288afebf",
   "metadata": {},
   "source": [
    "- scale data\n",
    "- explore thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e93fb-1dcc-4d96-ac46-305aa98c344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, auc, classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54283637-eb02-4acb-95c1-3f92eaaf5ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=10000, class_weight=\"balanced\", random_state=42)\n",
    "model.fit(X_train1, y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6b8c5-3bed-4971-a24a-9492c6dd28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(X=None, model=None):\n",
    "    y_pred = model.predict(X)\n",
    "    y_probas = model.predict_proba(X)\n",
    "    return y_probas, y_pred\n",
    "yhat, y_pred = predictions(X=X_train1, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b61cd-93c1-4f05-9642-342d54ce347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_probs = yhat[:, 1]\n",
    "precision, recall, threshold = precision_recall_curve(y_train0.astype(int), pos_probs)\n",
    "auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c84b6f-d478-47b1-b831-cf38352ba0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "isplay = PrecisionRecallDisplay.from_predictions(\n",
    "    y_test0, y_score, name=\"LinearSVC\", plot_chance_level=True\n",
    ")\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb7c794-217f-4070-b493-69d525e4c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    model, X_test1, y_test0, name=\"LogReg\", plot_chance_level=True\n",
    ")\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a76d7-9fe6-4036-9bde-6f1c4bf63ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_probs = yhat[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_train0.astype(int), pos_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print(f\"prauc: {auc_score}\")\n",
    "print(classification_report(y_train0, y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff74c04-f169-4525-99da-3af9570bb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train1)\n",
    "yhat = model.predict_proba(X_train1)\n",
    "pos_probs = yhat[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_train0.astype(int), pos_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "# print(confusion_matrix(y_train0, y_pred))\n",
    "print(f\"prauc: {auc_score}\")\n",
    "print(classification_report(y_train0, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cf30e-070d-4360-9383-5344e20bcf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(y_train0, y_pred, labels=model.classes_),\n",
    "    display_labels=model.classes_\n",
    ")\n",
    "disp.plot(cmap=\"Blues\", values_format=\"\", colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05569b4-14fa-4d50-a84a-b938dc2ae4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test1)\n",
    "yhat = model.predict_proba(X_test1)\n",
    "pos_probs = yhat[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_test0.astype(int).values, pos_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print(f\"prauc: {auc_score}\")\n",
    "# print(confusion_matrix(y_test0, y_pred))\n",
    "print(classification_report(y_test0, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c460c1-1b08-4ee1-a5f8-c204b47ed5e4",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779ebad-443d-4f5f-b49c-bfb3a228647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46582325-e046-4371-a056-0bcd8f1aa2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.3,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    criterion=\"gini\"\n",
    ")\n",
    "model.fit(X_train1, y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17baaeea-2ebb-4569-9f4d-16d4f7385f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train1)\n",
    "yhat = model.predict_proba(X_train1)\n",
    "pos_probs = yhat[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_train0.astype(int).values, pos_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print(f\"prauc: {auc_score}\")\n",
    "# print(confusion_matrix(y_train0, y_pred))\n",
    "print(classification_report(y_train0, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa97cc-e835-41fb-a028-c50cc3cb3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test1)\n",
    "yhat = model.predict_proba(X_test1)\n",
    "pos_probs = yhat[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_test0.astype(int).values, pos_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print(f\"prauc: {auc_score}\")\n",
    "# print(confusion_matrix(y_test0, y_pred))\n",
    "print(classification_report(y_test0, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114a231-05aa-4b4b-b267-fd047ddcb153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "453b583f-9a98-493a-85bc-b9d506e2ea69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Single category column EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93522d72-e354-49bf-9ad8-e1130c8a1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train1.describe(include=\"object\").drop([\"education\", \"tax filer stat\", \"detailed household and family stat\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18604d7-ca52-45a9-a208-781c203a6c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6df92-d874-4a3e-b73e-cb79e3b636a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"detailed household summary in household\"\n",
    "# print(df_train1[col].value_counts())\n",
    "ct = categorical_target_eda(dataframe=df_train1, column=col, plot=False)\n",
    "s = ct[\"50000+\"] - ct[\"- 50000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47efacff-f598-44cf-ae48-41b8ba53a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remap = {}\n",
    "threshold = 0.01\n",
    "for category, value in zip(s.index, s):\n",
    "    if value > threshold:\n",
    "        remap[category] = \"gt\"\n",
    "    elif value < -threshold:\n",
    "        remap[category] = \"lt\"\n",
    "    else:\n",
    "        remap[category] = \"eq\"\n",
    "\n",
    "df_train_remap = remap_cat_column(dataframe=df_train1, column=col, remap=remap)\n",
    "ct = categorical_target_eda(dataframe=df_train_remap, column=col, order=[\"lt\", \"eq\", \"gt\"])\n",
    "df_test_remap = remap_cat_column(dataframe=df_test1, column=col, remap=remap)\n",
    "ct = categorical_target_eda(dataframe=df_test_remap, column=col, order=[\"lt\", \"eq\", \"gt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2ebd8-2173-4948-b764-070bc041e5e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b527e1-bc86-4c49-a7a8-9fff52294c53",
   "metadata": {},
   "source": [
    "### descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a564945-74e6-4721-8059-9744072c5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302521b-b93d-4cfb-b01d-a121aaedf1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8c7bd-a2ec-4a48-b9da-96647eabf921",
   "metadata": {},
   "source": [
    "### plot categorical distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ccfb2-5fea-498d-8130-ed01fa7e78ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df_train1.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de00c61-ef4b-4ac6-8c64-c37d1ad5f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    n = df_train1[col].nunique()\n",
    "    if n <= 22:\n",
    "        sns.countplot(\n",
    "            y=col,\n",
    "            data=df_train1,\n",
    "            hue=col,\n",
    "            palette=sns.color_palette(palette=\"colorblind\", n_colors=n),\n",
    "            legend=False\n",
    "        )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51916c8a-bbb7-4237-8485-6496589e75bf",
   "metadata": {},
   "source": [
    "### slice target by categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a4206-cfc7-4ec9-80f7-acf148b33c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    if df_train1[col].nunique() <=4:\n",
    "        display(pd.crosstab(df_train1['target'], df_train1[col], normalize='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5fd4e4-a8e8-4b6e-9859-30c3427f36b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    if df_train1[col].nunique() <= 4:\n",
    "        g = sns.catplot(x = col, kind='count', col = 'target', data=df_train1, sharey=False)\n",
    "        g.set_xticklabels(rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e6978-498c-4203-b703-057499799eb5",
   "metadata": {},
   "source": [
    "### slice target by numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b874e8c0-dece-4d2f-ad4a-522ac6d32316",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df_train1.select_dtypes(float).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ed41b-2395-45d9-83da-b61bd0d6514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    df_train1[col].hist(bins=20)\n",
    "    print(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355a4ef-2e1c-41d5-a31f-580ce0503505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    sns.boxplot(\n",
    "        y=df_train1['target'].astype('category'),\n",
    "        hue=df_train1['target'].astype('category'),\n",
    "        x=col,\n",
    "        data=df_train1,\n",
    "        palette=sns.color_palette(palette=\"colorblind\", n_colors=2)\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28709db7-22cb-4ff0-93b3-11ebceb0e353",
   "metadata": {},
   "source": [
    "### Group numerical features (mean) by categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999ff13-5ed5-4ab5-9fa6-12f124dac44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    if df_train1[col].nunique() <= 3:\n",
    "        display(df_train1.groupby(col)[num_cols].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ac562-7b8f-4370-acbb-1df47adfdc86",
   "metadata": {},
   "source": [
    "### Correlation matrix for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa5f85-4b94-4d84-b75b-895be38e52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_train1.select_dtypes(float).corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70d738-0a2f-46e5-824c-a68cc2a18373",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(corr, cmap='RdBu_r', annot=True, vmax=1, vmin=-1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
